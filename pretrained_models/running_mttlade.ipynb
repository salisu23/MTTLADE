{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/salisu23/MTTLADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd MTTLADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash pretrained_models/convert_tf_to_pt.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! sed -i 's/ade_prepro.py/ade_prepro.py\\\\/' ade_prepro.sh\n",
    "! bash ade_prepro.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py \\\n",
    "  --init_checkpoint pretrained_models/pytorch_model.bin \\\n",
    "  --task_def ade_task_def.yml \\\n",
    "  --train_datasets \"n2c2source,n2c2relation\" \\\n",
    "  --test_datasets \"n2c2source,n2c2relation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash inference.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ade_prepro.py\n",
    "#train.py\n",
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if encoder_type == EncoderModelType.ERNIE:\n",
    "      model = AutoModel.from_pretrained(\"nghuyong/ernie-2.0-base-en\")\n",
    "      for param in model.parameters():\n",
    "          param.required_grad = False\n",
    "      state_dict = model.load_state_dict(torch.load(\"pytorch_model.bin\"),strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Macher SANBERT class after robarta\n",
    " elif opt['encoder_type'] == EncoderModelType.ERNIE:\n",
    "            from transformers import ErnieModel\n",
    "            self.bert = ErnieModel.from_pretrained(opt['init_checkpoint'])\n",
    "            hidden_size = self.bert.args.encoder_embed_dim\n",
    "            self.pooler = LinearPooler(hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #util in ade extraction tac colab\n",
    " len_t = (int(start_n)-start_txt)+int(len_text)\n",
    "ValueError: invalid literal for int() with base 10: 'cardiomyopathy'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
